export interface Resource {
  id: number;
  category: string;
  name: string;
  algorithm: string;
  computational: string;
  neuralNetworkArchitecture: string;
  mlPipeline: string;
  implementation: string;
  species: string;
}

export const resources: Resource[] = [
  // General Tools
  {
    id: 1,
    category: "General Tools",
    name: "idtracker.ai",
    algorithm: "Multi-animal identity tracking and maintenance across video recordings",
    computational: "Deep learning-based individual identification without markers (up to 100 animals)",
    neuralNetworkArchitecture: "CNN (Convolutional Neural Network)",
    mlPipeline: "Supervised learning with identity re-identification",
    implementation: "Open-source software",
    species: "Multi-species (general purpose)",
  },
  {
    id: 2,
    category: "General Tools",
    name: "SimBA - Simple Behavioral Analysis",
    algorithm: "Supervised behavioral classification from pose data",
    computational: "Machine learning classifiers trained on user-annotated behaviors",
    neuralNetworkArchitecture: "N/A (uses traditional ML classifiers)",
    mlPipeline: "Supervised learning; user annotates behaviors → trains classifier (Random Forest, XGBoost, etc.) → predicts on new data",
    implementation: "Python with GUI; supports DLC, DeepPoseKit, SLEAP, MARS inputs",
    species: "Multi-species (general purpose)",
  },
  {
    id: 3,
    category: "General Tools",
    name: "Bonsai",
    algorithm: "Real-time heterogeneous data stream synchronization and processing",
    computational: "Visual dataflow programming with reactive extensions",
    neuralNetworkArchitecture: "N/A (infrastructure tool)",
    mlPipeline: "N/A (infrastructure tool)",
    implementation: "Visual programming language (.NET-based)",
    species: "Multi-species (general purpose)",
  },
  {
    id: 4,
    category: "General Tools",
    name: "LabStreamingLayer (LSL)",
    algorithm: "Multi-source data streaming and temporal synchronization",
    computational: "Network-based middleware for time-stamped data alignment",
    neuralNetworkArchitecture: "N/A (infrastructure tool)",
    mlPipeline: "N/A (infrastructure tool)",
    implementation: "Cross-platform C++ library with language bindings",
    species: "Multi-species (general purpose)",
  },
  {
    id: 5,
    category: "General Tools",
    name: "Open Ephys",
    algorithm: "Electrophysiology data acquisition and real-time processing",
    computational: "Modular signal processing pipeline for neural recordings",
    neuralNetworkArchitecture: "N/A (hardware/acquisition tool)",
    mlPipeline: "N/A (hardware/acquisition tool)",
    implementation: "Open-source hardware and C++ software platform",
    species: "Multi-species (general purpose)",
  },
  {
    id: 6,
    category: "General Tools",
    name: "DeepLabCut",
    algorithm: "Markerless pose estimation of user-defined body parts across species",
    computational: "Transfer learning with ResNet-based CNNs for keypoint detection",
    neuralNetworkArchitecture: "CNN (ResNet-50, ResNet-101, EfficientNet variants)",
    mlPipeline: "Transfer learning: Pre-trained ImageNet weights → fine-tune on user-labeled frames (~200 frames) → predict keypoints on new videos → optional active learning iteration",
    implementation: "Python (TensorFlow/PyTorch); GUI available",
    species: "Multi-species (mice, rats, primates, horses, birds, fish, humans, etc.)",
  },
  {
    id: 7,
    category: "General Tools",
    name: "SLEAP (Social LEAP Estimates Animal Poses)",
    algorithm: "Multi-animal pose tracking without markers",
    computational: "Deep learning (top-down and bottom-up approaches) for body landmark estimation",
    neuralNetworkArchitecture: "CNN (LEAP CNN, UNet, ResNet backbones)",
    mlPipeline: "Supervised learning: User labels frames → trains centroid + instance models → predicts poses → tracks identities across frames",
    implementation: "Python (TensorFlow); GUI and API",
    species: "Multi-species (general purpose)",
  },
  {
    id: 8,
    category: "General Tools",
    name: "DeepPoseKit",
    algorithm: "Animal pose estimation from video",
    computational: "Deep learning with stacked hourglass networks or DenseNet",
    neuralNetworkArchitecture: "CNN (Stacked Hourglass, DenseNet)",
    mlPipeline: "Supervised learning: User annotates keypoints → trains encoder-decoder network → predicts on new frames",
    implementation: "Python (TensorFlow/Keras)",
    species: "Multi-species (general purpose)",
  },
  {
    id: 9,
    category: "General Tools",
    name: "JAABA (Janelia Automatic Animal Behavior Annotator)",
    algorithm: "Automated behavior classification from video features",
    computational: "Supervised machine learning (Gentle AdaBoost) on per-frame features",
    neuralNetworkArchitecture: "N/A (uses boosting, not neural networks)",
    mlPipeline: "Supervised learning: Extract per-frame features (motion, posture) → user annotates behaviors → trains Gentle AdaBoost classifier → predicts behavior labels → iterative refinement",
    implementation: "MATLAB",
    species: "Drosophila (fruit flies) - originally developed; adaptable to others",
  },
  {
    id: 10,
    category: "General Tools",
    name: "MARS (Mouse Action Recognition System)",
    algorithm: "Automated social behavior classification in mouse pairs",
    computational: "Deep learning for pose estimation + temporal action recognition (behaviors: attack, mounting, investigation)",
    neuralNetworkArchitecture: "CNN + LSTM/Temporal Convolutional Networks",
    mlPipeline: "Two-stage: (1) Pose estimation (CNN) → (2) Action classification (temporal model on pose sequences) with behavior annotations",
    implementation: "Python (PyTorch)",
    species: "Mouse (Mus musculus)",
  },
  {
    id: 11,
    category: "General Tools",
    name: "BENTO (Behavior Ensemble and Neural Trajectory Observatory)",
    algorithm: "Multimodal data synchronization and visualization for neurobehavioral analysis",
    computational: "Time-aligned integration of video, pose, neural, and audio streams",
    neuralNetworkArchitecture: "N/A (visualization/analysis tool)",
    mlPipeline: "N/A (visualization/analysis tool)",
    implementation: "MATLAB interface",
    species: "Multi-species (general purpose)",
  },
  {
    id: 12,
    category: "General Tools",
    name: "Motion Sequencing (MoSeq)",
    algorithm: "Unsupervised behavioral segmentation into reusable action 'syllables'",
    computational: "Autoregressive hidden Markov models on 3D depth-video motion features",
    neuralNetworkArchitecture: "N/A (uses AR-HMM, not neural networks)",
    mlPipeline: "Unsupervised learning: Extract 3D pose from depth video → PCA dimensionality reduction → AR-HMM identifies behavioral syllables → characterize syllable usage",
    implementation: "Python; depth camera hardware for data capture",
    species: "Mouse (Mus musculus) - primarily; adaptable to small rodents",
  },
  {
    id: 13,
    category: "General Tools",
    name: "OpenPose",
    algorithm: "Real-time multi-person 2D pose estimation (body, hands, face)",
    computational: "Part Affinity Fields (PAFs) with CNNs for keypoint detection and association",
    neuralNetworkArchitecture: "CNN (VGG-19 or MobileNet backbone with multi-stage refinement)",
    mlPipeline: "Supervised learning: Pre-trained on COCO/MPII datasets → predicts confidence maps for keypoints + PAFs for limb connections → greedy parsing for multi-person association",
    implementation: "C++ with Python API; GPU-accelerated",
    species: "Human (Homo sapiens)",
  },
  {
    id: 14,
    category: "General Tools",
    name: "OpenFace",
    algorithm: "Facial behavior analysis: landmarks, head pose, gaze, action units",
    computational: "Constrained Local Neural Fields (CLNF) and regression models for facial features",
    neuralNetworkArchitecture: "CNN (for some components) + CLNF (hybrid model)",
    mlPipeline: "Pre-trained models: Facial landmark detection → head pose estimation → eye gaze tracking → AU intensity estimation",
    implementation: "C++ with command-line tools",
    species: "Human (Homo sapiens)",
  },
  {
    id: 15,
    category: "General Tools",
    name: "DeepSqueak",
    algorithm: "Ultrasonic vocalization (USV) detection and analysis in rodents",
    computational: "CNN-based audio event detection with tonality features",
    neuralNetworkArchitecture: "CNN (operates on spectrogram images)",
    mlPipeline: "Supervised learning: Convert audio to spectrograms → CNN detects USV regions → classify call types → user can retrain with custom annotations",
    implementation: "MATLAB",
    species: "Mouse (Mus musculus), Rat (Rattus norvegicus)",
  },
  {
    id: 16,
    category: "General Tools",
    name: "Anipose",
    algorithm: "3D pose estimation from multi-camera views",
    computational: "Triangulation and calibration algorithms for 3D reconstruction from 2D poses",
    neuralNetworkArchitecture: "N/A (uses geometric methods; can integrate with DLC/SLEAP for 2D poses)",
    mlPipeline: "N/A (geometric triangulation; ML used only if 2D poses from DLC/SLEAP)",
    implementation: "Python",
    species: "Multi-species (general purpose)",
  },
  // Models
  {
    id: 17,
    category: "Models",
    name: "DeepLabCut Model Zoo (Mackenzie Mathis, Hugging Face)",
    algorithm: "Pre-trained pose estimation for diverse species",
    computational: "Transfer learning models (ResNet backbones) trained on species-specific datasets",
    neuralNetworkArchitecture: "CNN (ResNet-50, ResNet-101, EfficientNet variants)",
    mlPipeline: "Pre-trained models ready for transfer learning or direct inference; user can fine-tune on their data",
    implementation: "Python-compatible models (TensorFlow/PyTorch) hosted on Hugging Face",
    species: "Quadrupeds, mice, birds, humans, macaques, primates, horses",
  },
  {
    id: 18,
    category: "Models",
    name: "DeepLabCut Organization (Hugging Face)",
    algorithm: "Centralized repository of pose estimation models and demos",
    computational: "Pre-trained neural networks for animal pose across species",
    neuralNetworkArchitecture: "CNN (various ResNet and EfficientNet architectures)",
    mlPipeline: "Pre-trained models for direct use or fine-tuning",
    implementation: "Hugging Face model hub (Python-accessible)",
    species: "Quadrupeds, birds, humans, multi-species",
  },
  {
    id: 19,
    category: "Models",
    name: "CEBRA",
    algorithm: "Dimensionality reduction revealing hidden structures in neural time series",
    computational: "Contrastive learning with auxiliary behavioral variables for consistent embeddings",
    neuralNetworkArchitecture: "CNN or MLP encoders (customizable)",
    mlPipeline: "Self-supervised/semi-supervised contrastive learning: Neural data + behavior labels → learn low-dimensional embeddings that separate behavioral states",
    implementation: "Python (PyTorch)",
    species: "Multi-species (general purpose for neural data)",
  },
  // Datasets
  {
    id: 20,
    category: "Datasets",
    name: "SuperAnimal-Quadruped-80K",
    algorithm: "Large-scale training data for quadruped pose models",
    computational: "Aggregated labeled images for transfer learning",
    neuralNetworkArchitecture: "N/A (dataset)",
    mlPipeline: "Training dataset: 80K labeled images for supervised pose estimation model training",
    implementation: "Image dataset (compatible with DLC/SLEAP)",
    species: "Quadrupeds (dogs, cats, horses, etc.)",
  },
  {
    id: 21,
    category: "Datasets",
    name: "SuperAnimal-TopViewMouse-5K",
    algorithm: "Training data for top-view mouse pose estimation",
    computational: "Labeled mouse images for model training",
    neuralNetworkArchitecture: "N/A (dataset)",
    mlPipeline: "Training dataset: 5K labeled images for supervised pose estimation",
    implementation: "Image dataset",
    species: "Mouse (Mus musculus)",
  },
  // Benchmarks
  {
    id: 22,
    category: "Benchmarks",
    name: "DeepLabCut Benchmarks",
    algorithm: "Standardized evaluation of pose estimation accuracy across scenarios",
    computational: "Ground-truth labeled test sets (TRI-MOUSE, PARENTING-MOUSE, etc.)",
    neuralNetworkArchitecture: "N/A (evaluation benchmark)",
    mlPipeline: "Test/validation datasets with ground truth for model evaluation (PCK, RMSE metrics)",
    implementation: "Public datasets with evaluation metrics",
    species: "Mouse (Mus musculus), Marmoset, Fish, Horse",
  },
  {
    id: 23,
    category: "Benchmarks",
    name: "Animal Pose Estimation Leaderboard",
    algorithm: "Comparative ranking of pose estimation methods",
    computational: "Standardized metrics (PCK, RMSE) across benchmark datasets",
    neuralNetworkArchitecture: "N/A (evaluation platform)",
    mlPipeline: "Standardized evaluation protocol for comparing model performance",
    implementation: "Web-based leaderboard",
    species: "Multi-species (varies by benchmark)",
  },
  {
    id: 24,
    category: "Benchmarks",
    name: "DeepLabCut Leaderboard",
    algorithm: "Performance comparison for DLC-based approaches",
    computational: "Benchmark-specific accuracy metrics",
    neuralNetworkArchitecture: "N/A (evaluation platform)",
    mlPipeline: "Standardized evaluation for DLC variants",
    implementation: "Online leaderboard platform",
    species: "Multi-species (varies by benchmark)",
  },
  // Papers & Protocols
  {
    id: 25,
    category: "Papers & Protocols",
    name: "Using DeepLabCut for 3D Markerless Pose Estimation",
    algorithm: "Multi-camera 3D pose estimation methodology",
    computational: "Triangulation of 2D poses with camera calibration",
    neuralNetworkArchitecture: "CNN (for 2D pose); geometric methods for 3D",
    mlPipeline: "Protocol: Train 2D pose models per camera → calibrate cameras → triangulate to 3D coordinates",
    implementation: "Protocol documentation (DLC-based)",
    species: "Multi-species (general methodology)",
  },
  {
    id: 26,
    category: "Papers & Protocols",
    name: "DeepLabCut: Markerless Pose Estimation",
    algorithm: "Foundational approach to animal pose tracking",
    computational: "Transfer learning with ResNets for keypoint localization",
    neuralNetworkArchitecture: "CNN (ResNet)",
    mlPipeline: "Transfer learning methodology for pose estimation",
    implementation: "Academic paper (methodology)",
    species: "Multi-species (general methodology)",
  },
  {
    id: 27,
    category: "Papers & Protocols",
    name: "DeeperCut: Multi-person Pose Estimation",
    algorithm: "Multiple individual pose estimation in crowded scenes",
    computational: "Integer linear programming for part-to-person association",
    neuralNetworkArchitecture: "CNN (ResNet backbone)",
    mlPipeline: "Two-stage: CNN detects body parts → ILP solves association problem for multi-person pose",
    implementation: "Research paper (human pose)",
    species: "Human (Homo sapiens)",
  },
  {
    id: 28,
    category: "Papers & Protocols",
    name: "BRAIN Initiative Data Sharing Ecosystem (2024)",
    algorithm: "Analysis of neuroscience data sharing infrastructure",
    computational: "Comparative evaluation of FAIR principles across 7 repositories",
    neuralNetworkArchitecture: "N/A (policy paper)",
    mlPipeline: "N/A (policy paper)",
    implementation: "Policy and systems analysis paper",
    species: "Multi-species (infrastructure for all neuroscience data)",
  },
];
